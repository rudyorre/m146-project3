{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Sample Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Since we don't expect you to learn an entirely new approach to predictive modeling for this project, we instead encourage you to work with the models you already are familiar with in Project 1. \n",
    "\n",
    "For this project the easiest approach will simply be to condense the time series data into new features (e.g., engineer a feature for last month's sales, rolling averages, etc.) which would then allow you to treat each row as it's own independent data point. \n",
    "\n",
    "You can then simply use this month's sales data as the label, drop it from your dataframe and run a regression on it. \n",
    "\n",
    "This is certainly not the only approach you can take, and we highly encourage you experimenting with alternatives. But if you're stuck, this will give you a framework for getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import numpy as np \n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data \n",
    "dataunits = pd.read_csv('data/BrandTotalUnits.csv')\n",
    "datasales = pd.read_csv('data/BrandTotalSales.csv')\n",
    "datasales.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first issue is the data in its current form isn't really useful to us, so let's do some conversion of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First convert our months to datetime\n",
    "dataunits['Months'] = pd.to_datetime(dataunits['Months'])\n",
    "#Total units is too large currently to convert to a float\n",
    "#need to trim it first then convert to float\n",
    "dataunits['Total Units'] = dataunits['Total Units'].str.replace(',','')\n",
    "dataunits['Total Units'] = dataunits['Total Units'].str[:8]\n",
    "dataunits['Total Units'] = pd.to_numeric(dataunits['Total Units'])\n",
    "\n",
    "\n",
    "dataunits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First convert our months to datetime\n",
    "datasales['Months'] = pd.to_datetime(datasales['Months'])\n",
    "#Total units is too large currently to convert to a float\n",
    "#need to trim it first then convert to float\n",
    "datasales['Total Sales ($)'] = datasales['Total Sales ($)'].str.replace(',','')\n",
    "datasales['Total Sales ($)'] = datasales['Total Sales ($)'].str[:8]\n",
    "datasales['Total Sales ($)'] = pd.to_numeric(datasales['Total Sales ($)'])\n",
    "\n",
    "\n",
    "datasales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeSeries Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's a number of ways of approaching this but given the complexity of multiple brands with overlapping time intervals what seems to work easiest for me is breaking the dataset up by brand, engineering the features you want for each brand, and then reassembling the new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = dataunits[\"Brands\"].unique()\n",
    "brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for brand in brands:\n",
    "    ...\n",
    "#once you've successfully completed your feature engineering for \n",
    "#a single brand you can try wrapping it in a for loop to engineer \n",
    "#all brand features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now I'l attempt to construct some features on a single brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = dataunits[dataunits.Brands == '101 Cannabis Co.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now create two features based on sales history. I'm going to take last month's sales, as well as a rolling average of sales for the last three months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new dataframe from consumption column\n",
    "#data_historic = units[['Total Units']]\n",
    "# inserting new column with yesterday's consumption values\n",
    "units.loc[:,'Previous Month'] = units.loc[:,'Total Units'].shift(+1)\n",
    "# inserting another column with difference between yesterday and day before yesterday's consumption values.\n",
    "\n",
    "units.loc[:,'Rolling Average'] = (units.loc[:,'Total Units'].shift(+1) + units.loc[:,'Total Units'].shift(+2) + units.loc[:,'Total Units'].shift(+3))/3\n",
    "\n",
    "\n",
    "units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have only one brand to work with at a time, it's relatively trivial to merge our datasets and pull features from the other datasets. You can use this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = datasales[datasales.Brand == '101 Cannabis Co.']\n",
    "\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = units.merge(sales, left_on='Months', right_on='Months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = units.drop(['Brand'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I have a dataframe with merged features and engineered features. I now want to read in some brand specific features to augment my dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brand Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we have here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branddetails = pd.read_csv('data/BrandDetails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branddetails = branddetails[branddetails.Brand == '101 Cannabis Co.']\n",
    "\n",
    "branddetails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have a theory that it's important to determine if a company offers inhaleable and edible products as part of their product inventory so I'm going to create binary categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "value = 0\n",
    "value1 = 0\n",
    "\n",
    "if 'Inhaleables' in branddetails['Category L1'].values:\n",
    "    value = 1\n",
    "if 'Edibles' in branddetails['Category L1'].values:\n",
    "    value1 = 1\n",
    " \n",
    "units['Inhaleables'] = value\n",
    "units['Edible'] = value1\n",
    "\n",
    "\n",
    "units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also believe that a total count of the number of products the brand offers is also a useful feature to include. Fortunately that's easy enough to determine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productcount = (branddetails.Brand == '101 Cannabis Co.').count()\n",
    "\n",
    "productcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units['ProdCount'] = productcount\n",
    "\n",
    "units.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is starting to look like a pretty darn good dataframe! We now have merged and engineered timeseries features, along with brand-level features included in our dataframe. \n",
    "\n",
    "To complete this work the next steps will be to: \n",
    "\n",
    "1. finalize our feature selection plan\n",
    "2. consolidate these steps into a concise for loop for all brands and then append them into a single dataframe\n",
    "3. finalize an imputation strategy\n",
    "4. You can then treat the dataset like a typical regression problem where 'TotalSales' or 'TotalUnits' can be the label you predict on\n",
    "5. As always report your metrics! (and speaking of metrics, I found this handy-dandy helper functin that spits out a bunch of useful ones for you...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "def regression_results(y_true, y_pred):\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
